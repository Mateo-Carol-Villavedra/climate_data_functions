ind_meta <- read.csv("github/Example_metadata.csv")
str(ind_meta)
ind_meta <- read.csv("climate_data_functions/Example_metadata.csv")
ind_meta <- read.csv("climate_data_functions/test_dataset/Example_metadata.csv")
getwd()
ind_meta <- read.csv("climate_data_functions/test_dataset/Example_metadata.csv")
ind_meta <- read.csv("test_dataset/Example_metadata.csv")
str(ind_meta)
make_cell_centroids_df(template = "D:/Mateo/OneDrive - Macquarie University/2 - Tisiphone Abeona Project/Analysis/github/clim_data/daily_rain/processed/daily_rain_2019_processed.nc",
sample_df = ind_meta,
method = "grid",
directory = "test_dataset")
make_cell_centroids_df <- function(template = NULL,
sample_df = NULL,
method = "grid",
directory) {
# Loading Required Packages:
library(terra)
library(sf)
library(tidyverse)
# Function if the user is converting a grid to centroids based on the shapefile;
if(method == "grid") {
if(is.null(template)) {
stop("Template Raster Required for Method = Grid ")
}
# Load in the template raster - Band 1:
template_rast <- terra::rast(template)
# getting the resolution of the template:
resolution <- res(template_rast)[1]
# Converting each cell to a centroid point
pts <- terra::xyFromCell(template_rast, 1:ncell(template_rast))
# Assigning a centroid ID
centroids_df <- data.frame(centroid.id = 1:nrow(pts),
lat = pts$y,
lon = pts$x)
# Saving the Object and Returning it to the user:
write.csv(centroids_df, paste0(directory, "/region.grid_centroids_res=", resolution, ".csv"))
return(centroids_df)
} else if(method == "sample") {
if(is.null(template)) {
stop("Template Raster Required for Method = Sample ")
}
if(is.null(sample_df)) {
stop("Sample Locations Required for Method = Sample")
}
# Load in the template raster - Band 1:
template_rast <- terra::rast(template)
# getting the resolution of the template:
resolution <- res(template_rast)[1]
centroids_df <- sample_df %>%
rename(raw_lat = lat,
raw_lon = lon)
mutate(lon = round(raw_lat / resolution) * resolution,
lat = round(raw_lat / resolution) * resolution) %>%
distinct(lat, lon) %>%
mutate(centroid.id = row_number())
# Saving the Object and Returning it to the user:
write.csv(centroids_df, paste0(directory, "/sample_centroids_res=", resolution, ".csv"))
return(centroids_df)
} else {
stop("Method must be 'grid' or 'sample'")
}
ind_meta <- read.csv("test_dataset/Example_metadata.csv")
str(ind_meta)
make_cell_centroids_df(template = "D:/Mateo/OneDrive - Macquarie University/2 - Tisiphone Abeona Project/Analysis/github/clim_data/daily_rain/processed/daily_rain_2019_processed.nc",
sample_df = ind_meta,
method = "grid",
directory = "test_dataset")
test.rast <- terra::rast("D:/Mateo/OneDrive - Macquarie University/2 - Tisiphone Abeona Project/Analysis/github/clim_data/daily_rain/processed/daily_rain_2019_processed.nc")
test.rast
test.xy.rast <- terra::xyFromCell(test.rast, 1:ncell(test.rast))
test.xy.rast
test.xy.rast["x"]
str(test.xy.rast)
test.xy.rast$y
test.xy.rast <- as.data.frame(terra::xyFromCell(test.rast, 1:ncell(test.rast)))
test.xy.rast
test.xy.rast$x
nrow(distinct(test.xy.rast, x, y))
make_cell_centroids_df <- function(template = NULL,
sample_df = NULL,
method = "grid",
directory) {
# Loading Required Packages:
library(terra)
library(sf)
library(tidyverse)
# Function if the user is converting a grid to centroids based on the shapefile;
if(method == "grid") {
if(is.null(template)) {
stop("Template Raster Required for Method = Grid ")
}
# Load in the template raster - Band 1:
template_rast <- terra::rast(template)
# getting the resolution of the template:
resolution <- res(template_rast)[1]
# Converting each cell to a centroid point
pts <- as.data.frame(terra::xyFromCell(template_rast, 1:ncell(template_rast)))
# Assigning a centroid ID
centroids_df <- data.frame(centroid.id = 1:nrow(pts), lat = pts$y, lon = pts$x)
# Saving the Object and Returning it to the user:
write.csv(centroids_df, paste0(directory, "/region.grid_centroids_res=", resolution, ".csv"))
return(centroids_df)
} else if(method == "sample") {
if(is.null(template)) {
stop("Template Raster Required for Method = Sample ")
}
if(is.null(sample_df)) {
stop("Sample Locations Required for Method = Sample")
}
# Load in the template raster - Band 1:
template_rast <- terra::rast(template)
# getting the resolution of the template:
resolution <- res(template_rast)[1]
centroids_df <- sample_df %>%
rename(raw_lat = lat,
raw_lon = lon)
mutate(lon = round(raw_lat / resolution) * resolution,
lat = round(raw_lat / resolution) * resolution) %>%
distinct(lat, lon) %>%
mutate(centroid.id = row_number())
# Saving the Object and Returning it to the user:
write.csv(centroids_df, paste0(directory, "/sample_centroids_res=", resolution, ".csv"))
return(centroids_df)
} else {
stop("Method must be 'grid' or 'sample'")
}
ind_meta <- read.csv("test_dataset/Example_metadata.csv")
str(ind_meta)
make_cell_centroids_df(template = "D:/Mateo/OneDrive - Macquarie University/2 - Tisiphone Abeona Project/Analysis/github/clim_data/daily_rain/processed/daily_rain_2019_processed.nc",
sample_df = ind_meta,
method = "grid",
directory = "test_dataset")
make_cell_centroids_df <- function(template = NULL,
sample_df = NULL,
method = "grid",
directory) {
# Loading Required Packages:
library(terra)
library(sf)
library(tidyverse)
# Function if the user is converting a grid to centroids based on the shapefile;
if(method == "grid") {
if(is.null(template)) {
stop("Template Raster Required for Method = Grid ")
}
# Load in the template raster - Band 1:
template_rast <- terra::rast(template)
# getting the resolution of the template:
resolution <- res(template_rast)[1]
# Converting each cell to a centroid point
pts <- as.data.frame(template_rast[[1]], xy = TRUE, na.rm = TRUE)
# Assigning a centroid ID
centroids_df <- data.frame(centroid.id = 1:nrow(pts), lat = pts$y, lon = pts$x)
# Saving the Object and Returning it to the user:
write.csv(centroids_df, paste0(directory, "/region.grid_centroids_res=", resolution, ".csv"))
return(centroids_df)
} else if(method == "sample") {
if(is.null(template)) {
stop("Template Raster Required for Method = Sample ")
}
if(is.null(sample_df)) {
stop("Sample Locations Required for Method = Sample")
}
# Load in the template raster - Band 1:
template_rast <- terra::rast(template)
# getting the resolution of the template:
resolution <- res(template_rast)[1]
centroids_df <- sample_df %>%
rename(raw_lat = lat,
raw_lon = lon)
mutate(lon = round(raw_lat / resolution) * resolution,
lat = round(raw_lat / resolution) * resolution) %>%
distinct(lat, lon) %>%
mutate(centroid.id = row_number())
# Saving the Object and Returning it to the user:
write.csv(centroids_df, paste0(directory, "/sample_centroids_res=", resolution, ".csv"))
return(centroids_df)
} else {
stop("Method must be 'grid' or 'sample'")
}
ind_meta <- read.csv("test_dataset/Example_metadata.csv")
str(ind_meta)
make_cell_centroids_df(template = "D:/Mateo/OneDrive - Macquarie University/2 - Tisiphone Abeona Project/Analysis/github/clim_data/daily_rain/processed/daily_rain_2019_processed.nc",
sample_df = ind_meta,
method = "grid",
directory = "test_dataset")
test.centroids_grid <- make_cell_centroids_df(template = "D:/Mateo/OneDrive - Macquarie University/2 - Tisiphone Abeona Project/Analysis/github/clim_data/daily_rain/processed/daily_rain_2019_processed.nc",
sample_df = ind_meta,
method = "grid",
directory = "test_dataset")
nrow(test.centroids_grid)
extract_and_compile_clim.data <- function(var_directories,  centroid_df, output_filepath, check_crs = TRUE) {
# Ensuring all required packages are loaded:
library(sf)
library(terra)
library(tidyverse)
library(lubridate)
library(data.table)
# Checking user inputs are valid    ----
# Validate centroid_df structure
required_cols <- c("lat", "lon", "centroid.id")
missing_cols <- required_cols[!required_cols %in% names(centroid_df)]
if(length(missing_cols) > 0) {
stop(paste0("centroid_df missing required columns: ", paste(missing_cols, collapse = ", ")))
}
# Check that coordinates are numeric
if(!is.numeric(centroid_df$lat) | !is.numeric(centroid_df$lon)) {
stop("lat and lon columns must be numeric")
}
# Check coordinate ranges (should be within Australia roughly)
if(any(centroid_df$lat < -45 | centroid_df$lat > -10)) {
warning("Some latitude values outside typical Australian range (-45 to -10)")
}
if(any(centroid_df$lon < 110 | centroid_df$lon > 155)) {
warning("Some longitude values outside typical Australian range (110 to 155)")
}
# Check that directories exist
for(dir in var_directories) {
if(!dir.exists(dir)) {
stop(paste0("Directory does not exist: ", dir))
}
# Create output directory if needed
output_dir <- dirname(output_filepath)
if(!dir.exists(output_dir)) {
dir.create(output_dir, recursive = TRUE, showWarnings = FALSE)
}
message(paste0("Processing ", length(var_directories), " climate variables"))
message(paste0("Extracting data for ", nrow(centroid_df), " locations"))
#----
# Prepare spatial points for extraction ----
centroids_sf <- st_as_sf(centroid_df, coords = c("lon", "lat"), crs = 4326)
# Store original coordinates as data.table for fast binding
cent_coords_dt <- data.table( lat = centroid_df$lat, lon = centroid_df$lon, centroid.id = centroid_df$centroid.id )
#----
# Initialize storage for compiled data    ----
compiled_var_list <- list()
crs_summary <- data.frame(variable = character(), crs = character(),
n_files = integer(), stringsAsFactors = FALSE)
#----
# Loop through each climate variable directory
for(input_dir in var_directories) {
# Extract variable name from directory path
var_name <- basename(input_dir)
if(var_name %in% names(compiled_var_list)) {
warning(paste0("Variable '", var_name, "' already processed; skipping duplicate directory."))
next
}
message(paste0("\n=== Processing variable: ", var_name, " ==="))
# Detect file type and select appropriate files    ----
processed_dir <- file.path(input_dir, "processed")
rescaled_dir <- file.path(input_dir, "rescaled")
# Detect file type and select appropriate files
processed_files <- list.files(processed_dir, pattern = "\\.nc$", full.names = FALSE)
# Force use of rescaled files if they exist (for ANUCLIM)
rescaled_files <- list.files(rescaled_dir, pattern = "\\.nc$", full.names = FALSE)
if(length(rescaled_files) > 0) {
message("  Using rescaled files")
files_to_process <- rescaled_files
file_dir <- rescaled_dir
} else {
message("  Using Original Resolution files")
files_to_process <- processed_files
file_dir <- processed_dir
}
if(length(files_to_process) == 0) {
warning(paste0("No valid files found in ", input_dir))
next
}
message(paste0("  Found ", length(files_to_process), " files to process"))
#----
# Initialize list to store yearly data for this variable
yearly_data_list <- list()
var_crs_list <- c()
# Loop through each file (year) for this variable and process the raster stack:    ----
for(file_name in files_to_process) {
# Extract year from raster file
year <- str_extract(file_name, "\\d{4}")
if(is.na(year)) {
warning(paste0("Could not extract year from filename: ", file_name))
next
}
message(paste0("  Extracting year ", year))
tryCatch({
# Read the raster stack
raster_data <- terra::rast(file.path(file_dir, file_name))
# Store CRS
var_crs_list <- c(var_crs_list, as.character(crs(raster_data, proj = TRUE)))
# Transform centroids to raster CRS
centroids_sf_proj <- st_transform(centroids_sf, crs = crs(raster_data, proj = TRUE))
# Extract values (terra::extract returns a data.frame: first column = ID, rest = layers)
extracted_values <- terra::extract(raster_data, vect(centroids_sf_proj))
# Remove the ID column
values_mat <- as.matrix(extracted_values[,-1])
# Check if raster has multiple layers
n_layers <- ncol(values_mat)
n_centroids <- nrow(values_mat)
# Expand centroids for each layer
cent_expanded <- cent_coords_dt[rep(1:.N, times = n_layers)]
# Flatten values
values_vec <- as.vector(values_mat)
# Determine dates for layers
if (!is.null(terra::time(raster_data))) {
raster_dates <- as.IDate(terra::time(raster_data))
} else {
year <- str_extract(file_name, "\\d{4}")
raster_dates <- seq(as.IDate(paste0(year, "-01-01")), by = 1, length.out = n_layers)
}
dates_expanded <- rep(raster_dates, each = n_centroids)
# Build the final data.table
extracted_dt <- copy(cent_expanded)
extracted_dt[, (var_name) := values_vec]
extracted_dt[, clim_date := dates_expanded]
# Add to yearly list
yearly_data_list[[year]] <- extracted_dt
# Clean up
rm(raster_data, extracted_values)
gc()
}, error = function(e) {
warning(paste0("Error processing ", file_name, ": ", e$message))
})
}
#----
# CRS checking for this variable    ----
if(check_crs & length(var_crs_list) > 0) {
unique_crs <- unique(var_crs_list)
if(length(unique_crs) > 1) {
warning(paste0("Variable '", var_name, "' has files with different CRS:"))
for(crs_val in unique_crs) {
warning(paste0("  ", crs_val))
}
# Store CRS info for summary
crs_summary <- rbind(crs_summary,
data.frame(variable = var_name,
crs = unique_crs[1],
n_files = length(files_to_process),
stringsAsFactors = FALSE))
}
#----
# Reshape data for this variable    ----
if(length(yearly_data_list) == 0) {
warning(paste0("No data extracted for variable: ", var_name))
next
}
# Combine all yearly data.tables for this variable
all_years_dt <- rbindlist(yearly_data_list, use.names = TRUE, fill = TRUE)
# Already in long format: one column per variable + lat/lon/centroid.id/clim_date
compiled_var_list[[var_name]] <- all_years_dt
message(paste0("  Variable ", var_name, " complete: ", nrow(all_years_dt), " records"))
# Clean up
rm(yearly_data_list, all_years_dt)
gc()
#----
}   #  end variable loop
# Checking that data was successfully extracted from the rasters    ----
if(length(compiled_var_list) == 0) {
stop("No climate data was successfully extracted from any variable")
}
message(paste0("Combining ", length(compiled_var_list), " variables: ", paste(names(compiled_var_list), collapse = ", ")))
#----
# Ensuring that all variables have the consistent keys for the "full_join" to avoid duplication    ----
key_counts <- lapply(compiled_var_list, function(df) {
df %>%
distinct(lat, lon, centroid.id, clim_date) %>%
nrow()
})
diag_df <- data.frame(
variable = names(compiled_var_list),
n_keys = unlist(key_counts)
)
print(diag_df)
if(length(unique(diag_df$n_keys)) != 1) {
stop("⚠️ Not all variables have the same number of unique join keys. This may cause row duplication.")
}
#----
# Merge all variables using data.table ----
# Ensure all elements are data.tables
compiled_var_list <- lapply(compiled_var_list, as.data.table)
# New key columns for single-layer raster
key_cols <- c("lat", "lon", "centroid.id", "clim_date")
# Set keys for fast joining
lapply(compiled_var_list, setkeyv, key_cols)
# Merge all variables iteratively
all_clim_dt <- Reduce(function(x, y) merge(x, y, by = key_cols, all = TRUE),
compiled_var_list)
message(paste0("Total records after merging: ", nrow(all_clim_dt)))
#----
# Format date columns    ----
# Convert date column to proper Date object
all_clim_dt[, clim_date := as.IDate(clim_date)]
all_clim_dt[, clim_year := year(clim_date)]
all_clim_dt[, clim_month := month(clim_date)]
all_clim_dt[, clim_m.day := mday(clim_date)]
all_clim_dt[, clim_day.month := paste0(clim_m.day, ".", clim_month)]
all_clim_dt[, id := paste0(centroid.id, "_", year(clim_date))]
# Reorder columns
setcolorder(all_clim_dt, c("lat", "lon", "centroid.id", "id", "clim_date", "clim_year",
"clim_month", "clim_m.day", "clim_day.month",
setdiff(names(all_clim_dt), c("lat","lon","centroid.id","id",
"clim_date","clim_year",
"clim_month","clim_m.day","clim_day.month"))))
#----
# Save final compiled dataframe and output to user    ----
saveRDS(all_clim_dt, file = output_filepath)
message(paste0("Compiled climate data saved to: ", output_filepath))
return(all_clim_dt)
#-----
}
clim_dir <- c("D:/Mateo/OneDrive - Macquarie University/2 - Tisiphone Abeona Project/Analysis/github/clim_data/daily_rain",
"D:/Mateo/OneDrive - Macquarie University/2 - Tisiphone Abeona Project/Analysis/github/clim_data/radiation",
"D:/Mateo/OneDrive - Macquarie University/2 - Tisiphone Abeona Project/Analysis/github/clim_data/tmin",
"D:/Mateo/OneDrive - Macquarie University/2 - Tisiphone Abeona Project/Analysis/github/clim_data/tmax",
"D:/Mateo/OneDrive - Macquarie University/2 - Tisiphone Abeona Project/Analysis/github/clim_data/t_min",
"D:/Mateo/OneDrive - Macquarie University/2 - Tisiphone Abeona Project/Analysis/github/clim_data/t_max")
centroids <- read.csv("test_dataset/region.grid_centroids_res=0.05")
centroids <- read.csv("test_dataset/region.grid_centroids_res=0.05.csv")
str(centroids)
test_conversion <- extract_and_compile_clim.data(clim_dir, centroids, "test_dataset/compiled_raster_clim_df.RDS")
